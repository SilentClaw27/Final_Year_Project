{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages imported for the functions used\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sklearn as skl\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import IPython.display as ipd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn import svm, datasets\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import datetime\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the Directory of the Music Pieces i.e. choosing the subset\n",
    "AUDIO_DIR = \"fma_small\"\n",
    "\n",
    "#Loading the Data from the Dataset\n",
    "tracks = utils.load(\"fma_metadata/tracks.csv\")\n",
    "genres = utils.load(\"fma_metadata/genres.csv\")\n",
    "features = utils.load(\"fma_metadata/features.csv\")\n",
    "echonest = utils.load(\"fma_metadata/echonest.csv\")\n",
    "\n",
    "np.testing.assert_array_equal(features.index, tracks.index)\n",
    "assert echonest.index.isin(tracks.index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that encodes the music genre labels for each music piece\n",
    "def encodeData(train = \"test\"):\n",
    "    if train == \"training\":\n",
    "        for i in range(0,len(genres_low)):\n",
    "            ind = gen.loc[gen['genre_id'] == genres_low[i]].index[0]\n",
    "            \n",
    "            #Depending on the ind number, the value is given.\n",
    "            #i.e. 38 = [0], 15 = [1] etc\n",
    "            if ind == 38:\n",
    "                train_labels[x][0] = 1\n",
    "            elif ind == 15:\n",
    "                train_labels[x][1] = 1\n",
    "            elif ind == 12:\n",
    "                train_labels[x][2] = 1\n",
    "            elif ind == 1235:\n",
    "                train_labels[x][3] = 1\n",
    "            elif ind == 10:\n",
    "                train_labels[x][4] = 1\n",
    "            elif ind == 17:\n",
    "                train_labels[x][5] = 1\n",
    "            elif ind == 21:\n",
    "                train_labels[x][6] = 1\n",
    "            elif ind == 2:\n",
    "                train_labels[x][7] = 1\n",
    "            elif ind == 4:\n",
    "                train_labels[x][8] = 1\n",
    "            elif ind == 5:\n",
    "                train_labels[x][9] = 1\n",
    "            elif ind == 9:\n",
    "                train_labels[x][10] = 1\n",
    "            elif ind == 20:\n",
    "                train_labels[x][11] = 1\n",
    "            elif ind == 3:\n",
    "                train_labels[x][12] = 1\n",
    "            elif ind == 14:\n",
    "                train_labels[x][13] = 1\n",
    "            elif ind == 8:\n",
    "                train_labels[x][14] = 1\n",
    "            else:\n",
    "                train_labels[x][15] = 1\n",
    "    elif train == \"validation\":\n",
    "        for i in range(0,len(genres_low)):\n",
    "            ind = gen.loc[gen['genre_id'] == genres_low[i]].index[0]\n",
    "            if ind == 38:\n",
    "                validation_labels[x_val][0] = 1\n",
    "            elif ind == 15:\n",
    "                validation_labels[x_val][1] = 1\n",
    "            elif ind == 12:\n",
    "                validation_labels[x_val][2] = 1\n",
    "            elif ind == 1235:\n",
    "                validation_labels[x_val][3] = 1\n",
    "            elif ind == 10:\n",
    "                validation_labels[x_val][4] = 1\n",
    "            elif ind == 17:\n",
    "                validation_labels[x_val][5] = 1\n",
    "            elif ind == 21:\n",
    "                validation_labels[x_val][6] = 1\n",
    "            elif ind == 2:\n",
    "                validation_labels[x_val][7] = 1\n",
    "            elif ind == 4:\n",
    "                validation_labels[x_val][8] = 1\n",
    "            elif ind == 5:\n",
    "                validation_labels[x_val][9] = 1\n",
    "            elif ind == 9:\n",
    "                validation_labels[x_val][10] = 1\n",
    "            elif ind == 20:\n",
    "                validation_labels[x_val][11] = 1\n",
    "            elif ind == 3:\n",
    "                validation_labels[x_val][12] = 1\n",
    "            elif ind == 14:\n",
    "                validation_labels[x_val][13] = 1\n",
    "            elif ind == 8:\n",
    "                validation_labels[x_val][14] = 1\n",
    "            else:\n",
    "                validation_labels[x_val][15] = 1\n",
    "\n",
    "    else:\n",
    "        for i in range(0,len(genres_low)):\n",
    "            ind = gen.loc[gen['genre_id'] == genres_low[i]].index[0]\n",
    "            if ind == 38:\n",
    "                test_labels[x_test][0] = 1\n",
    "            elif ind == 15:\n",
    "                test_labels[x_test][1] = 1\n",
    "            elif ind == 12:\n",
    "                test_labels[x_test][2] = 1\n",
    "            elif ind == 1235:\n",
    "                test_labels[x_test][3] = 1\n",
    "            elif ind == 10:\n",
    "                test_labels[x_test][4] = 1\n",
    "            elif ind == 17:\n",
    "                test_labels[x_test][5] = 1\n",
    "            elif ind == 21:\n",
    "                test_labels[x_test][6] = 1\n",
    "            elif ind == 2:\n",
    "                test_labels[x_test][7] = 1\n",
    "            elif ind == 4:\n",
    "                test_labels[x_test][8] = 1\n",
    "            elif ind == 5:\n",
    "                test_labels[x_test][9] = 1\n",
    "            elif ind == 9:\n",
    "                test_labels[x_test][10] = 1\n",
    "            elif ind == 20:\n",
    "                test_labels[x_test][11] = 1\n",
    "            elif ind == 3:\n",
    "                test_labels[x_test][12] = 1\n",
    "            elif ind == 14:\n",
    "                test_labels[x_test][13] = 1\n",
    "            elif ind == 8:\n",
    "                test_labels[x_test][14] = 1\n",
    "            else:\n",
    "                test_labels[x_test][15] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that prepares a list before Encoding it\n",
    "def filLists(train = \"test\"):\n",
    "    #Use for loop to fill only 1 list full of 0s\n",
    "    if train == \"training\":\n",
    "        train_labels.append([])\n",
    "        \n",
    "        for c in range(0,16):\n",
    "            train_labels[x].append(0)\n",
    "    elif train == 'validation':\n",
    "        validation_labels.append([])\n",
    "\n",
    "        for c in range(0,16):\n",
    "            validation_labels[x_val].append(0)\n",
    "    else:\n",
    "        test_labels.append([])\n",
    "\n",
    "        for c in range(0,16):\n",
    "            test_labels[x_test].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that extracts the different features to be used for the SVM and RF models\n",
    "def feature_add(file, train = \"test\"):\n",
    "    mfcc1 = pd.DataFrame(features.index, index = features['mfcc', 'mean', '01'].values)\n",
    "    mfcc2 = pd.DataFrame(features.index, index = features['mfcc', 'mean', '02'].values)\n",
    "    mfcc3 = pd.DataFrame(features.index, index = features['mfcc', 'mean', '03'].values)\n",
    "\n",
    "    spec1 = pd.DataFrame(features.index, index = features['spectral_contrast', 'mean', '01'].values)\n",
    "    spec2 = pd.DataFrame(features.index, index = features['spectral_contrast', 'mean', '02'].values)\n",
    "    spec3 = pd.DataFrame(features.index, index = features['spectral_contrast', 'mean', '03'].values)\n",
    "\n",
    "    if(train == \"training\"):\n",
    "        features_train.append([])\n",
    "        for i in range(1,13):\n",
    "            if i == 10 or i == 11 or i == 12:\n",
    "                num = str(i)\n",
    "            else:\n",
    "                num = '0' + str(i)\n",
    "    \n",
    "            mfcc = pd.DataFrame(features.index, index = features['mfcc', 'mean', num].values)\n",
    "            stft = pd.DataFrame(features.index, index = features['chroma_stft', 'mean', num].values)\n",
    "            features_train[x].append(mfcc.loc[mfcc['track_id'] == file].index[0])\n",
    "            features_train[x].append(stft.loc[stft['track_id'] == file].index[0])\n",
    "            if i > 7:\n",
    "                continue\n",
    "            else:\n",
    "                spec = pd.DataFrame(features.index, index = features['spectral_contrast', 'std', num].values)\n",
    "                features_train[x].append(spec.loc[spec['track_id'] == file].index[0])\n",
    "      \n",
    "    elif(train == \"validation\"):\n",
    "        features_val.append([])\n",
    "        for i in range(1,13):\n",
    "            if i == 10 or i == 11 or i == 12:\n",
    "                num = str(i)\n",
    "            else:\n",
    "                num = '0' + str(i)\n",
    "    \n",
    "            mfcc = pd.DataFrame(features.index, index = features['mfcc', 'mean', num].values)\n",
    "            stft = pd.DataFrame(features.index, index = features['chroma_stft', 'mean', num].values)\n",
    "            features_val[x_val].append(mfcc.loc[mfcc['track_id'] == file].index[0])\n",
    "            features_val[x_val].append(stft.loc[stft['track_id'] == file].index[0])\n",
    "            if i > 7:\n",
    "                continue\n",
    "            else:\n",
    "                spec = pd.DataFrame(features.index, index = features['spectral_contrast', 'std', num].values)\n",
    "                features_val[x_val].append(spec.loc[spec['track_id'] == file].index[0])\n",
    "    else:\n",
    "        features_test.append([])\n",
    "        for i in range(1,13):\n",
    "            if i == 10 or i == 11 or i == 12:\n",
    "                num = str(i)\n",
    "            else:\n",
    "                num = '0' + str(i)\n",
    "    \n",
    "            mfcc = pd.DataFrame(features.index, index = features['mfcc', 'mean', num].values)\n",
    "            stft = pd.DataFrame(features.index, index = features['chroma_stft', 'mean', num].values)\n",
    "            features_test[x_test].append(mfcc.loc[mfcc['track_id'] == file].index[0])\n",
    "            features_test[x_test].append(stft.loc[stft['track_id'] == file].index[0])\n",
    "            if i > 7:\n",
    "                continue\n",
    "            else:\n",
    "                spec = pd.DataFrame(features.index, index = features['spectral_contrast', 'std', num].values)\n",
    "                features_test[x_test].append(spec.loc[spec['track_id'] == file].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp,elec,rock,instrum,pop,folk,hip,inter,jazz,classic,count,spok,blue,soul,old,easy = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "\n",
    "#Labels Lists\n",
    "train_labels = []\n",
    "validation_labels = []\n",
    "test_labels = []\n",
    "\n",
    "#Features Lists\n",
    "features_train = []\n",
    "features_val = []\n",
    "features_test = []\n",
    "\n",
    "#Id Lists\n",
    "train_id = []\n",
    "val_id = []\n",
    "test_id = []\n",
    "counter = 0\n",
    "\n",
    "#Counters used for the specific sections i.e. training, validation, and testing\n",
    "x = 0\n",
    "x_val = 0\n",
    "x_test = 0\n",
    "\n",
    "#Setting the Folder to be used for the Mel-Spectrograms\n",
    "if(AUDIO_DIR == 'fma_small'):\n",
    "    pic_folder = \"small\"\n",
    "elif(AUDIO_DIR == 'fma_medium'):\n",
    "    pic_folder = \"medium\"\n",
    "else:\n",
    "    pic_folder = \"full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop that scans each and every folder in the directory \n",
    "for folder in os.listdir(AUDIO_DIR):\n",
    "    if folder == \"checksums\" or folder == \"README.txt\":\n",
    "        continue\n",
    "    else:\n",
    "        full_folder_path = os.path.join(AUDIO_DIR, folder)\n",
    "        for file in os.listdir(full_folder_path):\n",
    "            counter += 1\n",
    "            train = True\n",
    "            if file == \"desktop.ini\": \n",
    "                continue\n",
    "            \n",
    "            #Creating the image path name\n",
    "            full_music_path = os.path.join(full_folder_path, file)\n",
    "            file_name = int(file.rsplit(\".\")[0])\n",
    "            pic_name = file.rsplit(\".\")[0] + '.png'\n",
    "\n",
    "            if pic_name not in os.listdir(pic_folder):\n",
    "                continue\n",
    "            \n",
    "            #Extracting the Top-Genre/s of the music piece\n",
    "            splits = pd.DataFrame(tracks.index, index=tracks['set', 'split'].values)\n",
    "            curr_split = splits.loc[splits['track_id'] == file_name].index[0]\n",
    "            \n",
    "            all_genres = pd.DataFrame(tracks.index, index=tracks['track', 'genres'].values)\n",
    "            genres_low = all_genres.loc[all_genres['track_id'] == file_name].index[0]\n",
    "            gen = pd.DataFrame(genres.index, index = genres['top_level'].values)\n",
    "\n",
    "            #Updating the Training, Validation, or Testing Id and Label lists\n",
    "            if curr_split == 'training':\n",
    "                train_id.append(pic_name)\n",
    "                filLists(\"training\")\n",
    "                encodeData(\"training\")\n",
    "                feature_add(file_name, \"training\")\n",
    "                x = x + 1\n",
    "            elif curr_split == 'validation':\n",
    "                val_id.append(pic_name)\n",
    "                filLists(\"validation\")\n",
    "                encodeData(\"validation\")\n",
    "                feature_add(file_name, \"validation\")\n",
    "                x_val = x_val + 1\n",
    "            else:\n",
    "                test_id.append(pic_name)\n",
    "                filLists(\"test\")\n",
    "                encodeData(\"test\")\n",
    "                feature_add(file_name, \"test\")\n",
    "                x_test = x_test + 1\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the three image dataframes\n",
    "data_train = pd.DataFrame({\n",
    "    'Image': train_id,\n",
    "    'Label 1': [l[0] for l in train_labels],\n",
    "    'Label 2': [l[1] for l in train_labels],\n",
    "    'Label 3': [l[2] for l in train_labels],\n",
    "    'Label 4': [l[3] for l in train_labels],\n",
    "    'Label 5': [l[4] for l in train_labels],\n",
    "    'Label 6': [l[5] for l in train_labels],\n",
    "    'Label 7': [l[6] for l in train_labels],\n",
    "    'Label 8': [l[7] for l in train_labels],\n",
    "    'Label 9': [l[8] for l in train_labels],\n",
    "    'Label 10': [l[9] for l in train_labels],\n",
    "    'Label 11': [l[10] for l in train_labels],\n",
    "    'Label 12': [l[11] for l in train_labels],\n",
    "    'Label 13': [l[12] for l in train_labels],\n",
    "    'Label 14': [l[13] for l in train_labels],\n",
    "    'Label 15': [l[14] for l in train_labels],\n",
    "    'Label 16': [l[15] for l in train_labels],\n",
    "})\n",
    "\n",
    "data_val = pd.DataFrame({\n",
    "    'Image': val_id,\n",
    "    'Label 1': [l[0] for l in validation_labels],\n",
    "    'Label 2': [l[1] for l in validation_labels],\n",
    "    'Label 3': [l[2] for l in validation_labels],\n",
    "    'Label 4': [l[3] for l in validation_labels],\n",
    "    'Label 5': [l[4] for l in validation_labels],\n",
    "    'Label 6': [l[5] for l in validation_labels],\n",
    "    'Label 7': [l[6] for l in validation_labels],\n",
    "    'Label 8': [l[7] for l in validation_labels],\n",
    "    'Label 9': [l[8] for l in validation_labels],\n",
    "    'Label 10': [l[9] for l in validation_labels],\n",
    "    'Label 11': [l[10] for l in validation_labels],\n",
    "    'Label 12': [l[11] for l in validation_labels],\n",
    "    'Label 13': [l[12] for l in validation_labels],\n",
    "    'Label 14': [l[13] for l in validation_labels],\n",
    "    'Label 15': [l[14] for l in validation_labels],\n",
    "    'Label 16': [l[15] for l in validation_labels],\n",
    "})\n",
    "\n",
    "data_test = pd.DataFrame({\n",
    "    'Image': test_id,\n",
    "    'Label 1': [l[0] for l in test_labels],\n",
    "    'Label 2': [l[1] for l in test_labels],\n",
    "    'Label 3': [l[2] for l in test_labels],\n",
    "    'Label 4': [l[3] for l in test_labels],\n",
    "    'Label 5': [l[4] for l in test_labels],\n",
    "    'Label 6': [l[5] for l in test_labels],\n",
    "    'Label 7': [l[6] for l in test_labels],\n",
    "    'Label 8': [l[7] for l in test_labels],\n",
    "    'Label 9': [l[8] for l in test_labels],\n",
    "    'Label 10': [l[9] for l in test_labels],\n",
    "    'Label 11': [l[10] for l in test_labels],\n",
    "    'Label 12': [l[11] for l in test_labels],\n",
    "    'Label 13': [l[12] for l in test_labels],\n",
    "    'Label 14': [l[13] for l in test_labels],\n",
    "    'Label 15': [l[14] for l in test_labels],\n",
    "    'Label 16': [l[15] for l in test_labels],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w = 369,496\n",
    "\n",
    "#ImageDataGenerator objects to extract the images and rescale them\n",
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "val_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#Flowing the images at a batch_size of 32 through the dataframes\n",
    "train_data = train_gen.flow_from_dataframe(\n",
    "    dataframe= data_train,\n",
    "    directory='medium',\n",
    "    x_col='Image',\n",
    "    y_col=['Label 1', 'Label 2', 'Label 3', 'Label 4', 'Label 5', 'Label 6', 'Label 7', 'Label 8', 'Label 9', 'Label 10', 'Label 11', 'Label 12', 'Label 13', 'Label 14', 'Label 15', 'Label 16'],\n",
    "    target_size=(h,w),\n",
    "    class_mode='raw',\n",
    "    batch_size=32,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_data = val_gen.flow_from_dataframe(\n",
    "    dataframe= data_val,\n",
    "    directory='medium',\n",
    "    x_col='Image',\n",
    "    y_col=['Label 1', 'Label 2', 'Label 3', 'Label 4', 'Label 5', 'Label 6', 'Label 7', 'Label 8', 'Label 9', 'Label 10', 'Label 11', 'Label 12', 'Label 13', 'Label 14', 'Label 15', 'Label 16'],\n",
    "    target_size=(h,w),\n",
    "    class_mode='raw',\n",
    "    batch_size=32,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "test_data = test_gen.flow_from_dataframe(\n",
    "    dataframe= data_test,\n",
    "    directory='medium',\n",
    "    x_col='Image',\n",
    "    y_col=['Label 1', 'Label 2', 'Label 3', 'Label 4', 'Label 5', 'Label 6', 'Label 7', 'Label 8', 'Label 9', 'Label 10', 'Label 11', 'Label 12', 'Label 13', 'Label 14', 'Label 15', 'Label 16'],\n",
    "    target_size=(h,w),\n",
    "    class_mode='raw',\n",
    "    batch_size=32,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the dataframes for the features\n",
    "feat_train = pd.DataFrame({\n",
    "    'Feature 1': [l[0] for l in features_train],\n",
    "    'Feature 2': [l[1] for l in features_train],\n",
    "    'Feature 3': [l[2] for l in features_train],\n",
    "    'Feature 4': [l[3] for l in features_train],\n",
    "    'Feature 5': [l[4] for l in features_train],\n",
    "    'Feature 6': [l[5] for l in features_train],\n",
    "    'Feature 7': [l[6] for l in features_train],\n",
    "    'Feature 8': [l[7] for l in features_train],\n",
    "    'Feature 9': [l[8] for l in features_train],\n",
    "    'Feature 10': [l[9] for l in features_train],\n",
    "    'Feature 11': [l[10] for l in features_train],\n",
    "    'Feature 12': [l[11] for l in features_train],\n",
    "    'Feature 13': [l[12] for l in features_train],\n",
    "    'Feature 14': [l[13] for l in features_train],\n",
    "    'Feature 15': [l[14] for l in features_train],\n",
    "    'Feature 16': [l[15] for l in features_train],\n",
    "    'Feature 17': [l[16] for l in features_train],\n",
    "    'Feature 18': [l[17] for l in features_train],\n",
    "    'Feature 19': [l[18] for l in features_train],\n",
    "    'Feature 20': [l[19] for l in features_train],\n",
    "    'Feature 21': [l[20] for l in features_train],\n",
    "    'Feature 22': [l[21] for l in features_train],\n",
    "    'Feature 23': [l[22] for l in features_train],\n",
    "    'Feature 24': [l[23] for l in features_train],\n",
    "    'Feature 25': [l[24] for l in features_train],\n",
    "    'Feature 26': [l[25] for l in features_train],\n",
    "    'Feature 27': [l[26] for l in features_train],\n",
    "    'Feature 28': [l[27] for l in features_train],\n",
    "    'Feature 29': [l[28] for l in features_train],\n",
    "    'Feature 30': [l[29] for l in features_train],\n",
    "    'Feature 31': [l[30] for l in features_train],\n",
    "})\n",
    "\n",
    "feat_val = pd.DataFrame({\n",
    "    'Feature 1': [l[0] for l in features_val],\n",
    "    'Feature 2': [l[1] for l in features_val],\n",
    "    'Feature 3': [l[2] for l in features_val],\n",
    "    'Feature 4': [l[3] for l in features_val],\n",
    "    'Feature 5': [l[4] for l in features_val],\n",
    "    'Feature 6': [l[5] for l in features_val],\n",
    "    'Feature 7': [l[6] for l in features_val],\n",
    "    'Feature 8': [l[7] for l in features_val],\n",
    "    'Feature 9': [l[8] for l in features_val],\n",
    "    'Feature 10': [l[9] for l in features_val],\n",
    "    'Feature 11': [l[10] for l in features_val],\n",
    "    'Feature 12': [l[11] for l in features_val],\n",
    "    'Feature 13': [l[12] for l in features_val],\n",
    "    'Feature 14': [l[13] for l in features_val],\n",
    "    'Feature 15': [l[14] for l in features_val],\n",
    "    'Feature 16': [l[15] for l in features_val],\n",
    "    'Feature 17': [l[16] for l in features_val],\n",
    "    'Feature 18': [l[17] for l in features_val],\n",
    "    'Feature 19': [l[18] for l in features_val],\n",
    "    'Feature 20': [l[19] for l in features_val],\n",
    "    'Feature 21': [l[20] for l in features_val],\n",
    "    'Feature 22': [l[21] for l in features_val],\n",
    "    'Feature 23': [l[22] for l in features_val],\n",
    "    'Feature 24': [l[23] for l in features_val],\n",
    "    'Feature 25': [l[24] for l in features_val],\n",
    "    'Feature 26': [l[25] for l in features_val],\n",
    "    'Feature 27': [l[26] for l in features_val],\n",
    "    'Feature 28': [l[27] for l in features_val],\n",
    "    'Feature 29': [l[28] for l in features_val],\n",
    "    'Feature 30': [l[29] for l in features_val],\n",
    "    'Feature 31': [l[30] for l in features_val],\n",
    "})\n",
    "\n",
    "feat_test = pd.DataFrame({\n",
    "    'Feature 1': [l[0] for l in features_test],\n",
    "    'Feature 2': [l[1] for l in features_test],\n",
    "    'Feature 3': [l[2] for l in features_test],\n",
    "    'Feature 4': [l[3] for l in features_test],\n",
    "    'Feature 5': [l[4] for l in features_test],\n",
    "    'Feature 6': [l[5] for l in features_test],\n",
    "    'Feature 7': [l[6] for l in features_test],\n",
    "    'Feature 8': [l[7] for l in features_test],\n",
    "    'Feature 9': [l[8] for l in features_test],\n",
    "    'Feature 10': [l[9] for l in features_test],\n",
    "    'Feature 11': [l[10] for l in features_test],\n",
    "    'Feature 12': [l[11] for l in features_test],\n",
    "    'Feature 13': [l[12] for l in features_test],\n",
    "    'Feature 14': [l[13] for l in features_test],\n",
    "    'Feature 15': [l[14] for l in features_test],\n",
    "    'Feature 16': [l[15] for l in features_test],\n",
    "    'Feature 17': [l[16] for l in features_test],\n",
    "    'Feature 18': [l[17] for l in features_test],\n",
    "    'Feature 19': [l[18] for l in features_test],\n",
    "    'Feature 20': [l[19] for l in features_test],\n",
    "    'Feature 21': [l[20] for l in features_test],\n",
    "    'Feature 22': [l[21] for l in features_test],\n",
    "    'Feature 23': [l[22] for l in features_test],\n",
    "    'Feature 24': [l[23] for l in features_test],\n",
    "    'Feature 25': [l[24] for l in features_test],\n",
    "    'Feature 26': [l[25] for l in features_test],\n",
    "    'Feature 27': [l[26] for l in features_test],\n",
    "    'Feature 28': [l[27] for l in features_test],\n",
    "    'Feature 29': [l[28] for l in features_test],\n",
    "    'Feature 30': [l[29] for l in features_test],\n",
    "    'Feature 31': [l[30] for l in features_test],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the labels for predictions and evaluation\n",
    "\n",
    "final_x_labels = []\n",
    "final_y_labels = []\n",
    "final_v_labels = []\n",
    "\n",
    "for l in train_labels:\n",
    "    final_x_labels.append(l.index(1))\n",
    "\n",
    "for v in validation_labels:\n",
    "    final_v_labels.append(v.index(1))\n",
    "\n",
    "for m in test_labels:\n",
    "    final_y_labels.append(m.index(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using all three base models and their predictions for the meta-model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model1 = keras.models.load_model('models/medium_model/')\n",
    "model2 = svm.SVC(kernel='poly', probability=True, degree=3, C=1)\n",
    "model3 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "model2.fit(feat_train,final_x_labels)\n",
    "model3.fit(feat_train,final_x_labels)\n",
    "\n",
    "pred1 = model1.predict(train_data)\n",
    "pred2 = model2.predict(feat_train)\n",
    "pred3 = model3.predict(feat_train)\n",
    "\n",
    "stacked_data = np.column_stack((pred1,pred2,pred3))\n",
    "\n",
    "meta = LogisticRegression(solver=\"lbfgs\", max_iter=200)\n",
    "meta.fit(stacked_data, final_x_labels)\n",
    "\n",
    "base1 = model1.predict(test_data)\n",
    "base2 = model2.predict(feat_test)\n",
    "base3 = model3.predict(feat_test)\n",
    "\n",
    "stacked_test_data = np.column_stack((base1,base2,base3))\n",
    "\n",
    "final_pred = meta.predict(stacked_test_data)\n",
    "\n",
    "accuracy = accuracy_score(final_y_labels, final_pred)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating a Confusion Matrix for the predictions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from sklearn import metrics\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(final_y_labels, final_pred)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix)\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
